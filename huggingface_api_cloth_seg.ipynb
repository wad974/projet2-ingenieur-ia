{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "intro_cell"
      },
      "source": [
        "# Guide pour l'Appel √† une API Hugging Face pour la Segmentation d'Images\n",
        "\n",
        "Bienvenue ! Ce notebook a pour but de vous guider pas √† pas dans l'utilisation de l'API d'inf√©rence de Hugging Face pour effectuer de la segmentation d'images. La segmentation d'images consiste √† attribuer une √©tiquette (comme \"cheveux\", \"v√™tement\", \"arri√®re-plan\") √† chaque pixel d'une image.\n",
        "\n",
        "Nous allons :\n",
        "1. Comprendre ce qu'est une API et comment s'y connecter.\n",
        "2. Envoyer une image √† un mod√®le de segmentation h√©berg√© sur Hugging Face.\n",
        "3. R√©cup√©rer et interpr√©ter les r√©sultats.\n",
        "4. Visualiser les masques de segmentation.\n",
        "5. √âtendre cela pour traiter plusieurs images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imports_intro_cell"
      },
      "source": [
        "## 1. Configuration Initiale et Importations\n",
        "\n",
        "Commen√ßons par importer les biblioth√®ques Python n√©cessaires. Nous aurons besoin de :\n",
        "- `os` pour interagir avec le syst√®me de fichiers (lister les images).\n",
        "- `requests` pour effectuer des requ√™tes HTTP vers l'API.\n",
        "- `PIL (Pillow)` pour manipuler les images.\n",
        "- `matplotlib.pyplot` pour afficher les images et les masques.\n",
        "- `numpy` pour la manipulation des tableaux (les images sont des tableaux de pixels).\n",
        "- `tqdm.notebook` pour afficher une barre de progression (utile pour plusieurs images).\n",
        "- `base64` et `io` pour d√©coder les masques renvoy√©s par l'API."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "imports_code_cell"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import requests\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tqdm.notebook import tqdm\n",
        "import base64\n",
        "import io"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "config_vars_intro_cell"
      },
      "source": [
        "### Variables de Configuration\n",
        "\n",
        "Nous devons d√©finir quelques variables :\n",
        "- `image_dir`: Le chemin vers le dossier contenant vos images. **Assurez-vous de modifier ce chemin si n√©cessaire.**\n",
        "- `max_images`: Le nombre maximum d'images √† traiter (pour ne pas surcharger l'API ou attendre trop longtemps).\n",
        "- `api_token`: Votre jeton d'API Hugging Face. **IMPORTANT : Gardez ce jeton secret !**\n",
        "\n",
        "**Comment obtenir un token API Hugging Face ?**\n",
        "1. Cr√©ez un compte sur [huggingface.co](https://huggingface.co/).\n",
        "2. Allez dans votre profil -> Settings -> Access Tokens.\n",
        "3. Cr√©ez un nouveau token (par exemple, avec le r√¥le \"read\").\n",
        "4. Copiez ce token ici."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "config_vars_code_cell"
      },
      "outputs": [],
      "source": [
        "# TODO: Modifiez ces valeurs selon votre configuration\n",
        "image_dir = \"/content/images_a_segmenter\"  # Exemple : si vous √™tes sur Colab et avez upload√© un dossier\n",
        "max_images = 3  # Commen√ßons avec peu d'images\n",
        "\n",
        "# IMPORTANT: Remplacez \"VOTRE_TOKEN_HUGGING_FACE_ICI\" par votre v√©ritable token API.\n",
        "# Ne partagez jamais votre token publiquement.\n",
        "api_token = \"VOTRE_TOKEN_HUGGING_FACE_ICI\"\n",
        "\n",
        "# Cr√©ons le dossier d'images s'il n'existe pas (pour l'exemple)\n",
        "if not os.path.exists(image_dir):\n",
        "    os.makedirs(image_dir)\n",
        "    print(f\"Dossier '{image_dir}' cr√©√©. Veuillez y ajouter des images .jpg ou .png.\")\n",
        "else:\n",
        "    print(f\"Dossier '{image_dir}' existant.\")\n",
        "\n",
        "if api_token == \"VOTRE_TOKEN_HUGGING_FACE_ICI\":\n",
        "    print(\"\\nATTENTION : Vous devez remplacer 'VOTRE_TOKEN_HUGGING_FACE_ICI' par votre token API personnel.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "api_understanding_cell"
      },
      "source": [
        "## 2. Comprendre l'API d'Inf√©rence Hugging Face\n",
        "\n",
        "L'API d'inf√©rence permet d'utiliser des mod√®les h√©berg√©s sur Hugging Face sans avoir √† les t√©l√©charger ou √† g√©rer l'infrastructure.\n",
        "\n",
        "- **Mod√®le utilis√©** : Nous allons utiliser le mod√®le `sayeed99/segformer_b3_clothes`, sp√©cialis√© dans la segmentation de v√™tements et de parties du corps.\n",
        "- **URL de l'API** : L'URL pour un mod√®le est g√©n√©ralement `https://api-inference.huggingface.co/models/NOM_DU_MODELE`.\n",
        "- **Headers (En-t√™tes)** : Pour s'authentifier et sp√©cifier le type de contenu, nous envoyons des en-t√™tes avec notre requ√™te.\n",
        "    - `Authorization`: Contient notre token API (pr√©c√©d√© de `Bearer `).\n",
        "    - `Content-Type`: Indique que nous envoyons une image au format JPEG (ou PNG selon le cas)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "api_setup_code_cell"
      },
      "outputs": [],
      "source": [
        "API_URL = \"https://api-inference.huggingface.co/models/...\" # Remplacez ... par le bon endpoint.\n",
        "headers = {\n",
        "    \"Authorization\": f\"Bearer {api_token}\"\n",
        "    # Le \"Content-Type\" sera ajout√© dynamiquement lors de l'envoi de l'image\n",
        "}\n",
        "\n",
        "# Lister les chemins des images √† traiter\n",
        "# Assurez-vous d'avoir des images dans le dossier 'image_dir'!\n",
        "image_paths = [] # A vous de jouer !\n",
        "\n",
        "\n",
        "if not image_paths:\n",
        "    print(f\"Aucune image trouv√©e dans '{image_dir}'. Veuillez y ajouter des images.\")\n",
        "else:\n",
        "    print(f\"{len(image_paths)} image(s) √† traiter : {image_paths}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "helper_functions_intro_cell"
      },
      "source": [
        "## 3. Fonctions Utilitaires pour le Traitement des Masques\n",
        "\n",
        "Le mod√®le que nous utilisons (`sayeed99/segformer_b3_clothes`) renvoie des masques pour diff√©rentes classes (cheveux, chapeau, etc.). Ces masques sont encod√©s en base64. Les fonctions ci-dessous sont fournies pour vous aider √† :\n",
        "1.  `CLASS_MAPPING`: Un dictionnaire qui associe les noms de classes (ex: \"Hat\") √† des identifiants num√©riques.\n",
        "2.  `get_image_dimensions`: R√©cup√©rer les dimensions d'une image.\n",
        "3.  `decode_base64_mask`: D√©coder un masque de base64 en une image (tableau NumPy) et le redimensionner.\n",
        "4.  `create_masks`: Combiner les masques de toutes les classes d√©tect√©es en un seul masque de segmentation final, o√π chaque pixel a la valeur de l'ID de sa classe.\n",
        "\n",
        "**Cette partie est donn√©e car elle est sp√©cifique au format de sortie de ce mod√®le et un peu complexe pour une premi√®re approche.** Lisez-la pour comprendre son r√¥le, mais ne vous attardez pas sur les d√©tails d'impl√©mentation pour l'instant."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "helper_functions_code_cell"
      },
      "outputs": [],
      "source": [
        "CLASS_MAPPING = {\n",
        "    \"Background\": 0,\n",
        "    \"Hat\": 1,\n",
        "    \"Hair\": 2,\n",
        "    \"Sunglasses\": 3,\n",
        "    \"Upper-clothes\": 4,\n",
        "    \"Skirt\": 5,\n",
        "    \"Pants\": 6,\n",
        "    \"Dress\": 7,\n",
        "    \"Belt\": 8,\n",
        "    \"Left-shoe\": 9,\n",
        "    \"Right-shoe\": 10,\n",
        "    \"Face\": 11,\n",
        "    \"Left-leg\": 12,\n",
        "    \"Right-leg\": 13,\n",
        "    \"Left-arm\": 14,\n",
        "    \"Right-arm\": 15,\n",
        "    \"Bag\": 16,\n",
        "    \"Scarf\": 17\n",
        "}\n",
        "\n",
        "def get_image_dimensions(img_path):\n",
        "    \"\"\"\n",
        "    Get the dimensions of an image.\n",
        "\n",
        "    Args:\n",
        "        img_path (str): Path to the image.\n",
        "\n",
        "    Returns:\n",
        "        tuple: (width, height) of the image.\n",
        "    \"\"\"\n",
        "    original_image = Image.open(img_path)\n",
        "    return original_image.size\n",
        "\n",
        "def decode_base64_mask(base64_string, width, height):\n",
        "    \"\"\"\n",
        "    Decode a base64-encoded mask into a NumPy array.\n",
        "\n",
        "    Args:\n",
        "        base64_string (str): Base64-encoded mask.\n",
        "        width (int): Target width.\n",
        "        height (int): Target height.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: Single-channel mask array.\n",
        "    \"\"\"\n",
        "    mask_data = base64.b64decode(base64_string)\n",
        "    mask_image = Image.open(io.BytesIO(mask_data))\n",
        "    mask_array = np.array(mask_image)\n",
        "    if len(mask_array.shape) == 3:\n",
        "        mask_array = mask_array[:, :, 0]  # Take first channel if RGB\n",
        "    mask_image = Image.fromarray(mask_array).resize((width, height), Image.NEAREST)\n",
        "    return np.array(mask_image)\n",
        "\n",
        "def create_masks(results, width, height):\n",
        "    \"\"\"\n",
        "    Combine multiple class masks into a single segmentation mask.\n",
        "\n",
        "    Args:\n",
        "        results (list): List of dictionaries with 'label' and 'mask' keys.\n",
        "        width (int): Target width.\n",
        "        height (int): Target height.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: Combined segmentation mask with class indices.\n",
        "    \"\"\"\n",
        "    combined_mask = np.zeros((height, width), dtype=np.uint8)  # Initialize with Background (0)\n",
        "\n",
        "    # Process non-Background masks first\n",
        "    for result in results:\n",
        "        label = result['label']\n",
        "        class_id = CLASS_MAPPING.get(label, 0)\n",
        "        if class_id == 0:  # Skip Background\n",
        "            continue\n",
        "        mask_array = decode_base64_mask(result['mask'], width, height)\n",
        "        combined_mask[mask_array > 0] = class_id\n",
        "\n",
        "    # Process Background last to ensure it doesn't overwrite other classes unnecessarily\n",
        "    # (Though the model usually provides non-overlapping masks for distinct classes other than background)\n",
        "    for result in results:\n",
        "        if result['label'] == 'Background':\n",
        "            mask_array = decode_base64_mask(result['mask'], width, height)\n",
        "            # Apply background only where no other class has been assigned yet\n",
        "            # This logic might need adjustment based on how the model defines 'Background'\n",
        "            # For this model, it seems safer to just let non-background overwrite it first.\n",
        "            # A simple application like this should be fine: if Background mask says pixel is BG, set it to 0.\n",
        "            # However, a more robust way might be to only set to background if combined_mask is still 0 (initial value)\n",
        "            combined_mask[mask_array > 0] = 0 # Class ID for Background is 0\n",
        "\n",
        "    return combined_mask"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "single_image_intro_cell"
      },
      "source": [
        "## 4. Segmentation d'une Seule Image\n",
        "\n",
        "Avant de traiter toutes les images, concentrons-nous sur une seule pour bien comprendre le processus.\n",
        "\n",
        "√âtapes :\n",
        "1.  Choisir une image.\n",
        "2.  Ouvrir l'image en mode binaire (`\"rb\"`) et lire son contenu (`data`).\n",
        "3.  D√©terminer le `Content-Type` (par exemple, `\"image/jpeg\"` ou `\"image/png\"`).\n",
        "4.  Envoyer la requ√™te POST √† l'API avec `requests.post()` en passant l'URL, les headers et les donn√©es.\n",
        "5.  V√©rifier le code de statut de la r√©ponse. Une erreur sera lev√©e si le code n'est pas 2xx (succ√®s) gr√¢ce √† `response.raise_for_status()`.\n",
        "6.  Convertir la r√©ponse JSON en un dictionnaire Python avec `response.json()`.\n",
        "7.  Utiliser nos fonctions `get_image_dimensions` et `create_masks` pour obtenir le masque final.\n",
        "8.  Afficher l'image originale et le masque segment√©."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "single_image_code_cell"
      },
      "outputs": [],
      "source": [
        "if image_paths:\n",
        "    single_image_path = image_paths[0] # Prenons la premi√®re image de notre liste\n",
        "    print(f\"Traitement de l'image : {single_image_path}\")\n",
        "\n",
        "    try:\n",
        "        # Lire l'image en binaire\n",
        "        # Et mettez le contenu de l'image dans la variable image_data\n",
        "        image_data = None # A vous de jouer !\n",
        "\n",
        "        # Maintenant, utilis√© l'API huggingface\n",
        "        # ainsi que les fonctions donn√©es plus haut pour s√©gmenter vos images.\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Une erreur est survenue : {e}\")\n",
        "else:\n",
        "    print(\"Aucune image √† traiter. V√©rifiez la configuration de 'image_dir' et 'max_images'.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "batch_intro_cell"
      },
      "source": [
        "## 5. Segmentation de Plusieurs Images (Batch)\n",
        "\n",
        "Maintenant que nous savons comment traiter une image, nous pouvons cr√©er une fonction pour en traiter plusieurs.\n",
        "Cette fonction va boucler sur la liste `image_paths` et appliquer la logique de segmentation √† chaque image.\n",
        "Nous utiliserons `tqdm` pour avoir une barre de progression."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "batch_code_cell"
      },
      "outputs": [],
      "source": [
        "def segment_images_batch(list_of_image_paths):\n",
        "    \"\"\"\n",
        "    Segmente une liste d'images en utilisant l'API Hugging Face.\n",
        "\n",
        "    Args:\n",
        "        list_of_image_paths (list): Liste des chemins vers les images.\n",
        "\n",
        "    Returns:\n",
        "        list: Liste des masques de segmentation (tableaux NumPy).\n",
        "              Contient None si une image n'a pas pu √™tre trait√©e.\n",
        "    \"\"\"\n",
        "    batch_segmentations = []\n",
        "\n",
        "    # N'oubliez pas de mettre une pause entre chaque appel API !\n",
        "\n",
        "\n",
        "    return batch_segmentations\n",
        "\n",
        "# Appeler la fonction pour segmenter les images list√©es dans image_paths\n",
        "if image_paths:\n",
        "    print(f\"\\nTraitement de {len(image_paths)} image(s) en batch...\")\n",
        "    batch_seg_results = segment_images_batch(image_paths)\n",
        "    print(\"Traitement en batch termin√©.\")\n",
        "else:\n",
        "    batch_seg_results = []\n",
        "    print(\"Aucune image √† traiter en batch.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "display_batch_intro_cell"
      },
      "source": [
        "## 6. Affichage des R√©sultats en Batch\n",
        "\n",
        "Nous allons maintenant cr√©er une fonction pour afficher les images originales et leurs segmentations correspondantes c√¥te √† c√¥te, dans une grille."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "display_batch_code_cell"
      },
      "outputs": [],
      "source": [
        "def display_segmented_images_batch(original_image_paths, segmentation_masks):\n",
        "    \"\"\"\n",
        "    Affiche les images originales et leurs masques segment√©s.\n",
        "\n",
        "    Args:\n",
        "        original_image_paths (list): Liste des chemins des images originales.\n",
        "        segmentation_masks (list): Liste des masques segment√©s (NumPy arrays).\n",
        "    \"\"\"\n",
        "    # Matplotlib, √ßa vous parle ?\n",
        "    # Alors... au travail ! üòâ\n",
        "\n",
        "# Afficher les r√©sultats du batch\n",
        "if batch_seg_results:\n",
        "    display_segmented_images_batch(image_paths, batch_seg_results)\n",
        "else:\n",
        "    print(\"Aucun r√©sultat de segmentation √† afficher.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "conclusion_cell"
      },
      "source": [
        "## Conclusion et Prochaines √âtapes\n",
        "\n",
        "F√©licitations ! Vous avez appris √† :\n",
        "- Configurer les appels √† l'API d'inf√©rence Hugging Face.\n",
        "- Envoyer des images pour la segmentation.\n",
        "- Interpr√©ter les r√©sultats (avec l'aide des fonctions fournies).\n",
        "- Visualiser les segmentations.\n",
        "\n",
        "Pistes d'am√©lioration ou d'exploration :\n",
        "- **Gestion d'erreurs plus fine** : Impl√©menter des tentatives multiples (retry) en cas d'√©chec de l'API (par exemple, si le mod√®le est en cours de chargement).\n",
        "- **Appels asynchrones** : Pour un grand nombre d'images, des appels asynchrones (avec `asyncio` et `aiohttp`) seraient beaucoup plus rapides.\n",
        "- **Autres mod√®les** : Explorer d'autres mod√®les de segmentation ou d'autres t√¢ches sur Hugging Face Hub.\n",
        "\n",
        "N'h√©sitez pas √† modifier le code, √† tester avec vos propres images et √† explorer davantage !\n",
        "\n",
        "**_Note_** : Si vous aimez ce mod√®le, n'h√©sitez pas √† le [t√©l√©charger](https://huggingface.co/sayeed99/segformer_b3_clothes) et jouer avec directement sur votre machine !"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TV_ctytI7EQn"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
